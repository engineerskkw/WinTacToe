{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.0.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketify(data, no_of_buckets, reduce_function):\n",
    "    bucket_size = len(data) // no_of_buckets\n",
    "\n",
    "    tmp = [[] for i in range(no_of_buckets)]\n",
    "\n",
    "    j = 0\n",
    "    for i in range(no_of_buckets):\n",
    "        for _ in range(bucket_size):\n",
    "            tmp[i].append(data[j])\n",
    "            j += 1\n",
    "\n",
    "    return [reduce_function(i) for i in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, inputs, targets, loss_func):\n",
    "    predictions = model(tf.constant(inputs))\n",
    "    return loss_func(y_pred=predictions, y_true=targets)\n",
    "\n",
    "def grad(model, inputs, targets, loss_func):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, loss_func)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "def train(model, dataset, epoches_no, optimiser, loss_func, train_loss_results=[]):\n",
    "    for epoch_no in range(epoches_no):\n",
    "#         if epoch_no==0:\n",
    "#         print(\"Epoch number: \")\n",
    "#         print(f\"{epoch_no}\", end=\" \")\n",
    "#         counter = 0\n",
    "        for x, y in dataset:\n",
    "#             if counter==0:\n",
    "#                 print(\"\\nminibatch number: \")\n",
    "#             print(f\"{counter}\", end=\" \")\n",
    "#             counter +=1\n",
    "            start = time.time()\n",
    "            features = np.array([x])\n",
    "            labels = np.array([y])\n",
    "            dataset_x = np.array([features])\n",
    "            dataset_y = np.array([labels])\n",
    "            end = time.time()\n",
    "#             print(f\"zero sek√≥nd: {end-start}\")\n",
    "            start = time.time()\n",
    "            loss_value, grads = grad(model, dataset_x, dataset_y, loss_func)\n",
    "            end = time.time()\n",
    "#             print(f\"grad: {end-start}\")\n",
    "            start = time.time()\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            end = time.time()\n",
    "#             print(f\"apply grad: {end-start}\")\n",
    "            train_loss_results.append(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES_NO = 100\n",
    "EPOCHES_NO = 1\n",
    "MINI_BATCH_NO = 1\n",
    "LEARNING_RATE = 0.005\n",
    "DECAY_RATE = LEARNING_RATE/EPOCHES_NO\n",
    "BATCH_SIZE = EXAMPLES_NO // MINI_BATCH_NO\n",
    "\n",
    "# DATASET\n",
    "RANGE = 5\n",
    "RANGE_UNIT = 2*np.pi\n",
    "EXPANSION = 1.1\n",
    "X = np.linspace(-RANGE*RANGE_UNIT, RANGE*RANGE_UNIT, EXAMPLES_NO).reshape(-1,1)\n",
    "X_expanded = np.linspace(-RANGE*RANGE_UNIT*EXPANSION, RANGE*RANGE_UNIT*EXPANSION, EXAMPLES_NO)\n",
    "Y = np.sin(X)/X\n",
    "X = np.array(X, dtype=np.float32)\n",
    "Y = np.array(Y, dtype=np.float32)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y)).batch(EXAMPLES_NO//MINI_BATCH_NO)\n",
    "\n",
    "# MODEL\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# OPTIMISER\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=LEARNING_RATE, decay=DECAY_RATE, momentum=0.1)\n",
    "\n",
    "# LOSS\n",
    "loss_func = tf.keras.losses.mean_squared_error\n",
    "\n",
    "# # CLASSICAL TRAINING\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy'])\n",
    "for _ in range(10000):\n",
    "    model.train_on_batch(X, Y)\n",
    "\n",
    "# # # RL TRAINING\n",
    "# %time train(model, dataset, EPOCHES_NO, optimizer, loss_func)\n",
    "\n",
    "# VISUALIZATION\n",
    "predictions = model.predict(X_expanded)\n",
    "plt.plot(X_expanded, predictions)\n",
    "plt.plot(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7-WinTacToe",
   "language": "python",
   "name": "python3.7-wintactoe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
